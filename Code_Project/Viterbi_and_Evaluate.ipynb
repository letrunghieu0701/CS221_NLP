{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HMM = {\n",
    "    'A':{\n",
    "        'sUN':0.625,\n",
    "        'sNN':0.125,\n",
    "        'sVB':0.125,\n",
    "        'sPRP':0.125,\n",
    "        \n",
    "        'UNUN':0.083333,\n",
    "        'UNNN':0.583333,\n",
    "        'UNVB':0.166667,\n",
    "        'UNPRP':0.166667,\n",
    "        \n",
    "        'NNUN':0.142857,\n",
    "        'NNNN':0.142857,\n",
    "        'NNVB':0.571429,\n",
    "        'NNPRP':0.142857,\n",
    "        \n",
    "        'VBUN':0.555556,\n",
    "        'VBNN':0.111111,\n",
    "        'VBVB':0.222222,\n",
    "        'VBPRP':0.111111,\n",
    "        \n",
    "        'PRPUN':0.25,\n",
    "        'PRPNN':0.25,\n",
    "        'PRPVB':0.25,\n",
    "        'PRPPRP':0.25,\n",
    "        \n",
    "        \n",
    "    },\n",
    "    'B':{\n",
    "        'UNcon':0.411764706,\n",
    "        'UNmèo':0.058823529,\n",
    "        'UNtrèo':0.058823529,\n",
    "        'UNcây':0.176470588,\n",
    "        'UNcau':0.058823529,\n",
    "        'UNchuột':0.058823529,\n",
    "        'UNhỏi':0.058823529,\n",
    "        'UNlà':0.058823529,\n",
    "        'UNnào':0.058823529,\n",
    "        'UNunknown1': 0.047619048,\n",
    "        'UNunknown2': 0.047619048,\n",
    "        'UNunknown3':0.047619048,\n",
    "        'UNunknown4':0.047619048,\n",
    "\n",
    "        \n",
    "        'NNcon':0.066666667,\n",
    "        'NNmèo':0.2,\n",
    "        'NNtrèo':0.066666667,\n",
    "        'NNcây':0.066666667,\n",
    "        'NNcau':0.2,\n",
    "        'NNchuột':0.2,\n",
    "        'NNhỏi':0.066666667,\n",
    "        'NNlà':0.066666667,\n",
    "        'NNnào':0.066666667,\n",
    "        'NNunknown1': 0.052631579,\n",
    "        'NNunknown2': 0.052631579,\n",
    "        'NNunknown3':0.052631579,\n",
    "        'NNunknown4':0.052631579,\n",
    "        \n",
    "        \n",
    "        'VBcon':0.066666667,\n",
    "        'VBmèo':0.071428571,\n",
    "        'VBtrèo':0.285714286,\n",
    "        'VBcây':0.071428571,\n",
    "        'VBcau':0.071428571,\n",
    "        'VBchuột':0.071428571,\n",
    "        'VBhỏi':0.142857143,\n",
    "        'VBlà':0.142857143,\n",
    "        'VBnào':0.071428571,\n",
    "        'VBunknown1': 0.055555556,\n",
    "        'VBunknown2': 0.055555556,\n",
    "        'VBunknown3':0.055555556,\n",
    "        'VBunknown4':0.055555556,\n",
    "        \n",
    "        'PRPcon':0.1,\n",
    "        'PRPmèo':0.1,\n",
    "        'PRPtrèo':0.1,\n",
    "        'PRPcây':0.1,\n",
    "        'PRPcau':0.1,\n",
    "        'PRPchuột':0.1,\n",
    "        'PRPhỏi':0.1,\n",
    "        'PRPlà':0.1,\n",
    "        'PRPnào':0.2,\n",
    "        'PRPunknown1': 0.071428571,\n",
    "        'PRPunknown2': 0.071428571,\n",
    "        'PRPunknown3':0.071428571,\n",
    "        'PRPunknown4':0.071428571\n",
    "        \n",
    "    },\n",
    "    'words':['con','mèo','trèo','cây','cau','chuột','hỏi','là','nào'],\n",
    "    'pos':['UN', 'NN', 'VB', 'PRP'],\n",
    "    'count_unknown': 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Viterbi(sentence, hidden_states):\n",
    "#### Khởi tạo Viterbi #####################\n",
    "    T = len(sentence.split())\n",
    "    N = len(HMM['pos'])\n",
    "    pos_of_sent = []\n",
    "    \n",
    "    sent_tokens = sentence.split()\n",
    "    viterbi = np.zeros(shape=(N, T))\n",
    "    back_pointer = np.zeros(shape=(N, T), dtype=np.int8)\n",
    "    # Khởi tạo xong #######################\n",
    "    \n",
    "    \n",
    "#### Bắt đầu tính toán cho Viterbi #####################\n",
    "    unk_word = 'unknown'\n",
    "    count_unknown = 0\n",
    "    first_word = sent_tokens[0]\n",
    "    \n",
    "#   Nếu xuất hiện unknown word thì lấy ra unknown word đầu tiên\n",
    "    if sent_tokens[0] not in HMM['words']:\n",
    "        count_unknown += 1\n",
    "        first_word = unk_word + str(count_unknown)\n",
    "        \n",
    "    # Tính toán cho từ đầu tiên trong câu\n",
    "    for s, pos in enumerate(HMM['pos']):\n",
    "        viterbi[s, 0] = HMM['A']['s'+pos] * HMM['B'][pos+first_word]\n",
    "        back_pointer[s, 0] = 0\n",
    "    \n",
    "    # Tính toán cho các từ tiếp theo trong câu\n",
    "    for t, word in enumerate(sent_tokens[1:]):\n",
    "        t = t+1\n",
    "        if word not in HMM['words']:\n",
    "#           Nếu vẫn còn unknown word chưa dùng thì chuyển sang unknown word tiếp theo để sử dụng\n",
    "            if count_unknown < HMM['count_unknown']:\n",
    "                count_unknown += 1\n",
    "            else: #           Nếu đã dùng hết các unknown word thì chuyển về dùng unknown word đầu tiên\n",
    "                count_unknown = 1\n",
    "                \n",
    "            word = unk_word + str(count_unknown)\n",
    "            \n",
    "        for s, pos in enumerate(HMM['pos']):\n",
    "            max_pos2pos2word = -999999\n",
    "            argmax = 0\n",
    "            for s_, pos_ in enumerate(HMM['pos']):\n",
    "                pos2pos2word = viterbi[s_][t-1] * HMM['A'][pos_+pos] * HMM['B'][pos+word]\n",
    "                if (pos2pos2word > max_pos2pos2word):\n",
    "                    max_pos2pos2word = pos2pos2word\n",
    "                    argmax = s_\n",
    "            viterbi[s, t] = max_pos2pos2word\n",
    "            back_pointer[s, t] = argmax\n",
    "    \n",
    "#     print(viterbi)\n",
    "    # Tính toán xong ####################################\n",
    "    \n",
    "#### Bắt đầu gán nhãn cho từng từ trong câu\n",
    "    # Lấy nhãn cho từ cuối trong câu\n",
    "    best_pos_ith_of_last_word = np.argmax(viterbi[:, T-1])\n",
    "    pos_of_last_word = HMM['pos'][best_pos_ith_of_last_word]\n",
    "\n",
    "\n",
    "    # Lấy back pointer của từ cuối trong câu\n",
    "    back_pointer_of_next_word = back_pointer[best_pos_ith_of_last_word, T-1]\n",
    "    back_pointer_of_next_word\n",
    "    \n",
    "    pos_of_sent.append(pos_of_last_word)\n",
    "#     print(best_pos_ith_of_last_word, pos_of_last_word)\n",
    "\n",
    "    for i in range(T-2, -1, -1):\n",
    "        # Lấy nhãn cho từ thứ i trong câu\n",
    "        best_pos_ith = back_pointer_of_next_word\n",
    "        pos = HMM['pos'][best_pos_ith]\n",
    "        pos_of_sent.append(pos)\n",
    "\n",
    "        # Lấy back pointer của từ thứ i trong câu\n",
    "        back_pointer_of_next_word = back_pointer[best_pos_ith, i]\n",
    "        back_pointer_of_next_word\n",
    "#         print(best_pos_ith, pos)\n",
    "        \n",
    "#   Đảo ngược thứ tự nhãn, vì Viterbi gán nhãn cho từ cuối cùng trong câu\n",
    "    pos_of_sent.reverse()\n",
    "    return pos_of_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['UN', 'NN', 'VB', 'VB', 'UN', 'NN']\n"
     ]
    }
   ],
   "source": [
    "sent = 'tôi trèo cây_cau với con mèo'\n",
    "pos_of_sent = Viterbi(sent, HMM['pos'])\n",
    "print(pos_of_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_labeled_data(file_name):\n",
    "    test_sentences = list()\n",
    "    label_of_sents = []\n",
    "\n",
    "    with open(file_name, \"r\", encoding='utf-8') as f:\n",
    "        content = f.readlines()\n",
    "        f.close()\n",
    "\n",
    "        for i in range(len(content)):\n",
    "            tagged_sentence = content[i].strip()\n",
    "            \n",
    "            tagged_sentence_token = []\n",
    "            label_of_sent = []\n",
    "            \n",
    "            for word_and_pos in tagged_sentence.split():\n",
    "                word, pos = word_and_pos.split('-')\n",
    "                \n",
    "                tagged_sentence_token.append(word)\n",
    "                label_of_sent.append(pos)\n",
    "\n",
    "            tagged_sentence = \" \".join(tagged_sentence_token)\n",
    "            test_sentences.append(tagged_sentence)\n",
    "            label_of_sents.append(label_of_sent)\n",
    "\n",
    "    return test_sentences, label_of_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag(sents):\n",
    "    pos_of_sents = []\n",
    "    for sent in sents:\n",
    "        pos_of_sent = Viterbi(sent, HMM['pos'])\n",
    "        pos_of_sents.append(pos_of_sent)\n",
    "\n",
    "    return pos_of_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_pos(pos_of_sent, pos_of_tagged_sent):\n",
    "    if len(pos_of_sent) != len (pos_of_tagged_sent):\n",
    "        print(\"Số lượng nhãn không đồng đều giữa dữ liệu test và ground truth !!!!!!!!!!!\")\n",
    "        return None\n",
    "    \n",
    "    count_correct_predicts = 0\n",
    "    for predict, label in zip(pos_of_sent, pos_of_tagged_sent):\n",
    "        if predict == label:\n",
    "            count_correct_predicts += 1\n",
    "\n",
    "    return count_correct_predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_acc(predicts_pos, label_of_sents):\n",
    "    count_correct_preds = 0\n",
    "    n_words = 0\n",
    "    for preds_pos, labels_pos in zip(predicts_pos, label_of_sents):\n",
    "        count = compare_pos(preds_pos, labels_pos)\n",
    "        if count != None:\n",
    "            count_correct_preds += count\n",
    "            n_words += len(preds_pos)\n",
    "        else:\n",
    "            return None\n",
    "            \n",
    "    return count_correct_preds / n_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Đọc data test:**<br>\n",
    "Lấy các từ và các nhãn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sents, label_of_sents = read_labeled_data('test_data_sample.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dự đoán nhãn cho các câu test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts_pos = tag(test_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tính độ đo Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_acc(predicts_pos, label_of_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
